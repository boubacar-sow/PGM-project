{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBe66--c9Vb_"
      },
      "source": [
        "## Imports and Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6SgGFbi9VcB",
        "outputId": "cd7b5762-3bf7-4295-8a44-8e7a9c070981"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import torch.optim as optim\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "from tqdm.notebook import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import Tuple\n",
        "from tqdm import tqdm\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "import random\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(0)\n",
        "hidden_width = 64\n",
        "torch.cuda.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_classes = 10\n",
        "latent_dims = 32\n",
        "hidden_channels = 12\n",
        "hidden_width = 64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def bayes_classifier(x, enc, dec, dimY, lowerbound, K = 1, beta=1.0):\n",
        "    N = x.shape[0]\n",
        "    logpxy = []\n",
        "    for i in range(dimY):\n",
        "        y = torch.zeros([N, dimY]).to(device)\n",
        "        y[:, i] = 1\n",
        "        bound = lowerbound(x, y,enc, dec, K,\n",
        "                           IS=True, beta=beta)\n",
        "        logpxy.append(torch.unsqueeze(bound, 1))\n",
        "    logpxy = torch.concat(logpxy, 1)\n",
        "    pyx = F.softmax(logpxy,dim=1)\n",
        "    return pyx\n",
        "def log_gaussian_prob(x, mu, log_sig):\n",
        "    logprob = -(0.5 * np.log(2 * np.pi) + log_sig) \\\n",
        "                - 0.5 * ((x - mu) / torch.exp(log_sig)) ** 2\n",
        "    ind = list(range(2, len(x.shape)))\n",
        "    return torch.sum(logprob, ind)\n",
        "\n",
        "\n",
        "def encoding(enc, x, y, K):\n",
        "    mu_qz, log_sig_qz = enc(x, y)\n",
        "    ph = torch.zeros([K]+list(mu_qz.shape))\n",
        "    norm_sample = torch.normal(ph).to(device)\n",
        "    samples = mu_qz+torch.unsqueeze(log_sig_qz.exp(), dim=0)*norm_sample\n",
        "    logq = log_gaussian_prob(samples, mu_qz.unsqueeze(0), log_sig_qz.unsqueeze(0))\n",
        "    return samples, logq\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, hidden_channels: int, latent_dim: int, num_labels: int) -> None:\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=1,\n",
        "            out_channels=hidden_channels,\n",
        "            kernel_size=4,\n",
        "            stride=2,\n",
        "            padding=1,\n",
        "        )\n",
        "\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            in_channels=hidden_channels,\n",
        "            out_channels=hidden_channels * 2,\n",
        "            kernel_size=4,\n",
        "            stride=2,\n",
        "            padding=1,\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(hidden_channels * 2 * 7 * 7 + num_labels, hidden_width)\n",
        "\n",
        "        self.fc_mu = nn.Linear(\n",
        "            in_features=hidden_width,\n",
        "            out_features=latent_dim,\n",
        "        )\n",
        "        self.fc_logvar = nn.Linear(\n",
        "            in_features=hidden_width,\n",
        "            out_features=latent_dim,\n",
        "        )\n",
        "\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "    def forward(\n",
        "        self, x: torch.Tensor, y: torch.Tensor\n",
        "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        h = self.activation(self.conv1(x))\n",
        "        h = self.activation(self.conv2(h))\n",
        "        h = h.view(h.size(0), -1)  # Flatten the tensor\n",
        "        h = torch.cat(\n",
        "            (h, y), dim=1\n",
        "        )\n",
        "        h = self.activation(self.fc(h))\n",
        "        mu = self.fc_mu(h)\n",
        "        logvar = self.fc_logvar(h)\n",
        "        return mu, logvar\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GFZ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BU0Ufoqx9VcD"
      },
      "outputs": [],
      "source": [
        "def lowerbound_gbz(x, y, enc, dec, K=1, IS=False,  beta=1.0):\n",
        "\n",
        "    z, logq = encoding(enc,x, y, K)\n",
        "    log_prior_z = log_gaussian_prob(z, torch.zeros_like(z), torch.zeros_like(z))\n",
        "\n",
        "    pxz, pyz = dec(torch.flatten(z,end_dim=1))\n",
        "    pxz = torch.stack(torch.tensor_split(pxz,K,dim=0),dim=0)\n",
        "    pyz = torch.stack(torch.tensor_split(pyz,K,dim=0),dim=0)\n",
        "    # print(pyz.shape)\n",
        "\n",
        "    ind = list(range(2, len(x.shape)+1))\n",
        "    logp = -torch.sum((x.unsqueeze(0) - pxz)**2, dim=ind)\n",
        "    logit_y = F.softmax(pyz,dim=2)\n",
        "\n",
        "    y_rep = torch.stack([y  for i in range(K)],dim=0)\n",
        "    log_pyz = -F.cross_entropy(logit_y.flatten(end_dim=1), y_rep.flatten(end_dim=1),\n",
        "                               reduction='none').reshape(y_rep.shape[:-1])\n",
        "    bound = logp * beta + log_pyz + (log_prior_z - logq)\n",
        "    if IS and K > 1:\n",
        "        bound = torch.logsumexp(bound,dim=0) - np.log(float(K))\n",
        "    return bound.squeeze()\n",
        "\n",
        "\n",
        "class Decoder_gbz(nn.Module):\n",
        "    def __init__(self, hidden_channels: int, latent_dim: int, num_labels: int) -> None:\n",
        "        super().__init__()\n",
        "        self.hidden_channels = hidden_channels\n",
        "\n",
        "        # MLP for p(y|z)\n",
        "        self.fc_py_z = nn.Linear(latent_dim, 500)\n",
        "        self.fc_py_z1 = nn.Linear(500, num_labels)\n",
        "\n",
        "        # MLP for p(x|z)\n",
        "        self.fc_px_z = nn.Linear(latent_dim, hidden_channels * 2 * 7 * 7)\n",
        "\n",
        "        self.conv2 = nn.ConvTranspose2d(\n",
        "            in_channels=hidden_channels * 2,\n",
        "            out_channels=hidden_channels,\n",
        "            kernel_size=4,\n",
        "            stride=2,\n",
        "            padding=1,\n",
        "        )\n",
        "        self.conv1 = nn.ConvTranspose2d(\n",
        "            in_channels=hidden_channels,\n",
        "            out_channels=1,\n",
        "            kernel_size=4,\n",
        "            stride=2,\n",
        "            padding=1,\n",
        "        )\n",
        "\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "    def forward(self, z: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        # Use the MLP to get the distribution over labels\n",
        "        y = self.activation(self.fc_py_z(z))\n",
        "        y = self.fc_py_z1(y)\n",
        "\n",
        "        h = self.activation(self.fc_px_z(z))\n",
        "        h = h.view(h.size(0), self.hidden_channels * 2, 7, 7)  # Reshape the tensor\n",
        "\n",
        "        # Use the rest of the decoder to get the reconstructed image\n",
        "        h = self.activation(self.conv2(h))\n",
        "        x_recon = torch.sigmoid(self.conv1(h))\n",
        "\n",
        "        return x_recon, y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DBX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class Decoder_dbx(nn.Module):\n",
        "    def __init__(self,latent_dim: int, num_labels: int, hidden_channels: int):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=1,\n",
        "            out_channels=hidden_channels,\n",
        "            kernel_size=4,\n",
        "            stride=2,\n",
        "            padding=1,\n",
        "        )\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            in_channels=hidden_channels,\n",
        "            out_channels=hidden_channels * 2,\n",
        "            kernel_size=4,\n",
        "            stride=2,\n",
        "            padding=1,\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden_channels * 2 * 7 * 7, hidden_width)\n",
        "        self.fc_mu = nn.Linear(\n",
        "            in_features=hidden_width,\n",
        "            out_features=latent_dim,\n",
        "        )\n",
        "        self.fc_logvar = nn.Linear(\n",
        "            in_features=hidden_width,\n",
        "            out_features=latent_dim,\n",
        "        )\n",
        "        self.fc_y = nn.Sequential(nn.Linear(latent_dim, hidden_width),\n",
        "                                  nn.ReLU(),\n",
        "                                  nn.Linear(hidden_width,num_labels))\n",
        "        \n",
        "\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "    def forward(\n",
        "        self, x: torch.Tensor, z: torch.Tensor\n",
        "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        h = self.activation(self.conv1(x))\n",
        "        h = self.activation(self.conv2(h))\n",
        "        h = h.view(h.size(0), -1)  # Flatten the tensor\n",
        "        h = self.activation(self.fc(h))\n",
        "        mu = self.fc_mu(h)\n",
        "        logvar = self.fc_logvar(h)\n",
        "        return mu, logvar, self.fc_y(z)\n",
        "\n",
        "\n",
        "def lowerbound_dbx(x, y, enc, dec, K=1, IS=False, beta=1.0):\n",
        " \n",
        "    z, logq = encoding(enc,x, y,K)\n",
        "    mu_pz, logsig_pz, logit_y = dec(x, torch.flatten(z, end_dim=1)) \n",
        "    logit_y = F.softmax(logit_y,dim=1)\n",
        "    logit_y = torch.stack(torch.tensor_split(logit_y,K,dim=0),dim=0)\n",
        "    \n",
        "    log_pzx = log_gaussian_prob(z, mu_pz, logsig_pz)\n",
        "\n",
        "    y_rep = torch.stack([y  for i in range(K)],dim=0)\n",
        "    log_pyz = -F.cross_entropy(logit_y.flatten(end_dim=1), y_rep.flatten(end_dim=1),\n",
        "                               reduction='none').reshape(y_rep.shape[:-1])    # mu_pz = tf.tile(mu_pz, [K, 1])\n",
        "    # print(log_pzx.shape, log_pyz.shape, logq.shape)\n",
        "    bound = log_pzx + log_pyz - beta * logq\n",
        "    if IS and K > 1:\n",
        "        bound = torch.logsumexp(bound,dim=0) - np.log(float(K))\n",
        "    return bound.squeeze()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xh8T1YbR9VcE"
      },
      "source": [
        "## Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-05-06T18:10:22.913231Z",
          "start_time": "2020-05-06T18:10:22.901495Z"
        },
        "id": "ks6n0GGhxsMD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/50 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "\n",
        "batch_size = 128\n",
        "learning_rate = 1e-5\n",
        "beta = 1\n",
        "img_transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "#to be switched\n",
        "lowerbound = lowerbound_dbx\n",
        "Decoder = Decoder_dbx\n",
        "\n",
        "\n",
        "encoder = Encoder(hidden_channels=hidden_channels,latent_dim=latent_dims,num_labels=num_classes).to(device)\n",
        "decoder = Decoder(hidden_channels=hidden_channels,latent_dim=latent_dims,num_labels=num_classes).to(device)\n",
        "optimizer1 = torch.optim.Adam(params=encoder.parameters(), lr=learning_rate)\n",
        "optimizer2 = torch.optim.Adam(params=decoder.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_dataset = MNIST(root='./data/MNIST', download=True, train=True, transform=img_transform)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_dataset = MNIST(root='./data/MNIST', download=True, train=False, transform=img_transform)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=max(10000, batch_size), shuffle=True)\n",
        "\n",
        "for epoch in tqdm(range(1, 50+1)):\n",
        "    # train_loss_averager = make_averager()\n",
        "    loss = []\n",
        "    Acc = []\n",
        "    for image_batch, labels in train_dataloader:\n",
        "        # print(image_batch.shape, labels.shape)\n",
        "        image_batch, labels = image_batch.to(device), labels.to(device)\n",
        "        bound = torch.mean(-lowerbound(image_batch,F.one_hot(labels,10).to(device).float(),encoder,decoder,K=2 ))\n",
        "\n",
        "        optimizer1.zero_grad()\n",
        "        optimizer2.zero_grad()\n",
        "\n",
        "        bound.backward()\n",
        "\n",
        "        # one step of the optmizer\n",
        "        optimizer1.step()\n",
        "        optimizer2.step()\n",
        "\n",
        "        preds = bayes_classifier(image_batch,encoder, decoder,10, lowerbound,K=10)\n",
        "        loss.append(bound.detach().item())\n",
        "        Acc.append(torch.mean((torch.argmax(preds, 1)==labels)*1.0).item())\n",
        "    print(sum(loss)/len(loss))\n",
        "    print(sum(Acc)/len(Acc))\n",
        "\n",
        "        "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
